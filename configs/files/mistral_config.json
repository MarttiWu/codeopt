{
    "generation_number": 5,
    "log_path": "./logs/codellama",
    "evaluation_path": "./evaluation/codellama",
    "lang": "python",
    "batch_size": 1,
    "max_seq_length": 2048,
    "max_new_tokens": 1024,
    "temperature": 0.7
}